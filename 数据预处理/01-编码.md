#编码

[[Preprocessing] Encoding Categorical Data | Kaggle](https://www.kaggle.com/code/ohseokkim/preprocessing-encoding-categorical-data)
[分类特征编码挑战 |卡格尔 (kaggle.com)](https://www.kaggle.com/c/cat-in-the-dat/overview)
[特征编码总结 Kaggle - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/117230627)
[【精选】深度盘点：类别型特征编码方法总结_类别特征编码-CSDN博客](https://blog.csdn.net/weixin_38037405/article/details/121722154?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-1-121722154-blog-109709967.235^v38^pc_relevant_sort_base2&spm=1001.2101.3001.4242.2&utm_relevant_index=4)
[【精选】Python之category-encoders：category-encoders库的简介、安装、使用方法之详细攻略_category_encoders_一个处女座的程序猿的博客-CSDN博客](https://blog.csdn.net/qq_41185868/article/details/109709967)
[【精选】深度盘点：类别型特征编码方法总结_类别特征编码-CSDN博客](https://blog.csdn.net/weixin_38037405/article/details/121722154?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-1-121722154-blog-109709967.235^v38^pc_relevant_sort_base2&spm=1001.2101.3001.4242.2&utm_relevant_index=4)


[Importance of Feature Scaling — scikit-learn 1.3.2 documentation](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html#sphx-glr-auto-examples-preprocessing-plot-scaling-importance-py)


### 1、平均数编码

参考资料：
> Micci-Barreca, Daniele. "A preprocessing scheme for high-cardinality categorical attributes in classification and prediction problems." ACM SIGKDD Explorations Newsletter 3.1 (2001): 27-32.

>代码实现：[平均数编码：针对高基数定性特征（类别特征）的数据预处理/特征工程 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/26308272)


适用条件：
（1）以大量不同值为特征的分类数据
（2）通常包含难以表示用于建模目的的潜在相关信息。
（3）对于具有固有层次结构的分类属性（如邮政编码），预该方案可以通过混合各种聚合级别的统计信息来直接利用层次结构

针对是否具有层级关系：[高基数类别特征预处理：平均数编码 | 京东云技术团队-CSDN博客](https://blog.csdn.net/JDDTechTalk/article/details/132579775?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-132579775-blog-78581462.235%5Ev38%5Epc_relevant_sort_base2&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-132579775-blog-78581462.235%5Ev38%5Epc_relevant_sort_base2&utm_relevant_index=1)
（1）单个类别特征编码
（2）层次结构如方位特征具有多种特征，可能具有多种层级

但值得注意的是，平均数编码可能会带来data leakage的问题：

**Target leakage**, also known as **data leakage**, is a common challenge in machine learning and data science. It occurs when information from the future (not available at prediction time) unintentionally influences the model during training.
1. **Definition:**
    
    - **Target leakage** happens when you train your algorithm on a dataset that includes features or information that would **not be available at the time of prediction** when applying the model to new data.
    - This leads to **overestimation** of the model’s performance during training, making it **useless** for real-world applications.
2. **Examples of Target Leakage:**
    
    - **Temporal Leakage**: Using future data (e.g., stock prices) to predict past events (e.g., stock trading decisions).
    - **Information Leakage**: Including features derived from the target variable (e.g., using the target variable itself or its transformations) in the training data.
    - **Data Collection Leakage**: Collecting additional data after observing the target variable (e.g., collecting customer feedback after knowing whether they churned).
3. **Impact of Target Leakage:**
    
    - **Inflated Performance**: Models appear better during training but fail to generalize to new, unseen data.
    - **False Confidence**: Decision-makers may rely on inaccurate model predictions due to target leakage.
    - **Unreliable Insights**: Feature importance and model interpretation can be misleading.
4. **Preventing Target Leakage:**
    
    - **Feature Engineering**: Ensure that features used for training are based only on information available at the time of prediction.
    - **Holdout Data**: Use separate validation or holdout data to evaluate model performance.
    - **Cross-Validation**: Perform cross-validation carefully to avoid data leakage.
    - **Domain Knowledge**: Understand the problem domain and the context of your data.
