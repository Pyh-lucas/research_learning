#相关性

主要参考资料：
[Statistical functions (scipy.stats) — SciPy v1.11.3 Manual](https://docs.scipy.org/doc/scipy/reference/stats.html)
[【精选】不同数据类型的相关性分析总结_分类变量与数值变量相关性_sikadeerlu的博客-CSDN博客](https://blog.csdn.net/baidu_26137595/article/details/124021788)
[❤️Pearson/Spearman/Kendallta三大相关系数怎么选？怎么计算？ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/411907389)
[不同变量类型下相关性分析的方法汇总——（慢慢更新完善） - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/600666493)

## 0 变量类型
	![Pasted image 20231111101120](https://peiyihan-1324725457.cos.ap-beijing.myqcloud.com/Obsidian/202403040853085.png?imageSlim)
	
	
	![Pasted image 20231111103307](https://peiyihan-1324725457.cos.ap-beijing.myqcloud.com/Obsidian/202403040853086.png?imageSlim)


## 1 数值型变量（numerical）之间的 相关系数

####    如何综合起来看三种相关系数？
>**一致性检查**：三种相关系数是否都同向，如果方向一致，则这种关系的方向更加可信
>**P-Value**：对每种相关系数的P值，显著小于显著性水平（一般取<0.05），则说明在该水平下有足够的证据来支持该相关性显著
>**散点图检查if necessary**：通过散点图的分布，能够更好识别相关关系的形式（尤其是非线性的斯皮尔曼和肯德尔这两个非线性相关系数），`但是对于大量数据集的时候散点图的表现力不强

####    三种相关系数的对比
>**Pearson**：衡量的是两个变量之间的线性关系，当两个变量之间的关系呈现出**直线**关系时，皮尔逊关系表现较好；但是如果关系是非线性的，那么用皮尔逊可能无法完全捕捉到这种关系
>**Spearman&Kendall**：二者均为非参数的相关系数，他们关注的是变量之间的单调关系，而不仅仅是线性关系。因此他们对发现非线性关系更为敏感。斯皮尔曼相关系数度量的是变量的等级之间的 关系，而肯德尔度量的是等级的关系的一种统计

####    进行相关系数之前的准备工作
- 缺失值处理
- 归一化处理[[02-无量纲化]]
	通常来说，如果数据分布相对正常，离群值不是很明显，可以先尝试进行相关性分析，观察结果。如果发现相关性受到异常值的影响，或者数据分布不均匀，可以考虑尝试不同的归一化方法



### （1）Pearson
**使用前提**：`大小一致、连续、服从正态分布的数据集`，以下为scipy中描述：

> **scipy.stats.pearsonr(x, y)**  
> The Pearson correlation coefficient measures the linear relationship between two datasets 「`衡量两组数据的线性相关性`」.  
>   
> The calculation of the p-value relies on the assumption that each dataset is normally distributed「`假设两组数据服从正态分布，即数据必须是连续型数据(continuous)`」.  
>   
> Like other correlation coefficients, this one varies between -1 and +1 with 0 implying no correlation. Correlations of -1 or +1 imply an exact linear relationship. Positive correlations imply that as x increases, so does y. Negative correlations imply that as x increases, y decreases.「`pearson相关系数范围为-1到1、负值为负相关、0为不相关、正值为正相关下图能很好的展示这种关系` 」


### （2）Spearman

**使用前提**：`皮尔逊Pearson相关系数使用前提条件中，任何一个条件不满足时可以考虑使用该系数`；  
  
Spearman与Pearson相关系数计算很类似，只是Spearman计算需要`将两个变量转化为序数`，以下为scipy中描述，

> **scipy.stats.spearmanr(a, b=None, axis=0, nan_policy='propagate')**  
> Calculate a Spearman correlation coefficient with associated p-value.The Spearman rank-order correlation coefficient is a nonparametric measure of the monotonicity of the relationship between two datasets「`两个变量成对取值并排序取秩`」. Unlike the Pearson correlation, the Spearman correlation does not assume that both datasets are normally distributed「`假设两组数据不需要服从正态分布`」.  
>   
> Like other correlation coefficients, this one varies between -1 and +1 with 0 implying no correlation. Correlations of -1 or +1 imply an exact monotonic relationship. Positive correlations imply that as x increases, so does y. Negative correlations imply that as x increases, y decreases「`相关系数范围为-1到1、负值为负相关、0为不相关`」.  
>   
> The p-value roughly indicates the probability of an uncorrelated system producing datasets that have a Spearman correlation at least as extreme as the one computed from these datasets. The p-values are not entirely reliable but are probably reasonable for datasets larger than 500 or so「`数据集元素大小大于500可能才靠谱`」.


### （3）Kendallta肯德尔相关系数

**使用前提**：和前两者比完全不一样，`衡量有序分类型数据的序数相关性`，以下为scipy中描述，

> **scipy.stats.kendalltau(x, y, initial_lexsort=None, nan_policy='propagate', method='auto')**  
>   
> Calculate Kendall’s tau, a correlation measure for ordinal data「`评估有序分类变量(ordinal data)的相关性`」.Kendall’s tau is a measure of the correspondence between two rankings「`衡量两组变量的等级相关性`」. Values close to 1 indicate strong agreement, values close to -1 indicate strong disagreement「`相关系数1为极度相关、-1不极度不相关`」.

### e.g.  我的数据集

首先通过平均数编码，将目标钢种描述转化为了连续的数值，接下来进行属性之间的相关性分析时：
（1）**Continuous Features:**
- If the other feature is continuous (numeric), you can treat the target-encoded variable as a **continuous feature**.
- 
（2）**Categorical Features:**
- If the other feature is also categorical, you can treat the target-encoded variable as a **categorical feature**.


|数据类型|详细类型|列名|
|---|---|---|---|
|categorical|nominal|首件标识|
|categorical|nominal|炉座号|
|categorical|ordinal|目标出钢量|
|categorical|nominal|是否浇余|
|numerical|continuous|C|
|numerical|continuous|Mn|
|numerical|continuous|P|
|numerical|continuous|S|
|numerical|continuous|Si|
|numerical|continuous|吹炼后温度|
|numerical|continuous|铁水量|
|numerical|continuous|废钢量|
|numerical|continuous|氧气用量|
|numerical|continuous|氩气用量_bof|
|numerical|continuous|连铸到台重量|
|numerical|continuous|坯料重量|
|categorical|nominal|班次_bof|
|categorical|nominal|班别_bof|
|categorical|nominal|作业人员_bof|
|numerical|continuous|处理次数|
|categorical|nominal|LF号|
|numerical|continuous|结束钢水量|
|numerical|continuous|氩气用量_lf|
|numerical|continuous|通电时间（秒）|
|numerical|continuous|通电量|
|categorical|nominal|班次_lf|
|categorical|nominal|班别_lf|
|categorical|nominal|作业人员_lf|
|categorical|nominal|RH机号|
|categorical|nominal|RH坑号|
|numerical|continuous|开始钢水量_rh|
|numerical|continuous|结束钢水量_rh|
|numerical|continuous|开始温度_rh|
|numerical|continuous|结束温度_rh|
|categorical|nominal|班次|
|categorical|nominal|班别|
|categorical|nominal|作业人员|
|categorical|nominal|连铸机号|
|categorical|nominal|RH真空处理|
|numerical|continuous|内控S含量|
|numerical|continuous|内控P含量|
|numerical|continuous|厚度(mm)|
|numerical|continuous|宽度(mm)|
|numerical|continuous|板坯总重(t)|
|numerical|continuous|计划块数|
|numerical|continuous|铁水装入量(t)|
|numerical|continuous|废钢装入量(t)|
|numerical|continuous|到达重量|
|numerical|continuous|离开重量|
|categorical|nominal|是否低磷钢|
|categorical|nominal|是否低碳钢|
|categorical|nominal|是否低硫钢|
|categorical|nominal|是否低磷低碳低硫钢|
|categorical|nominal|班次_cc|
|categorical|nominal|班别_cc|
|categorical|nominal|作业人员_cc|
|categorical|nominal|计划工艺路径|
|||Makespan（分钟）|
|numerical|continuous|炼钢时间（分钟）|
|||安装时间（分钟）|
|categorical|nominal|LF处理|
|categorical|nominal|是否缺少精炼处理|
|||RH时间（分钟）|
|numerical|平均数编码|steel_code|
|numerical|平均数编码|target_steel_code_rh|
（1）先用scipy判断各个数据集的分布，
sharpiry方法不能处理N>5000的情况？直接计算相关系数
[Scipy 显著性检验 | 菜鸟教程 (runoob.com)](https://www.runoob.com/scipy/scipy-significance-tests.html)
[SciPy documentation — SciPy v1.11.3 Manual](https://docs.scipy.org/doc/scipy/)
（2）再考虑不同类别间相关系数的处理

[不同变量类型下相关性分析的方法汇总——（慢慢更新完善） - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/600666493)
[【精选】不同数据类型的相关性分析总结_分类变量与数值变量相关性_sikadeerlu的博客-CSDN博客](https://blog.csdn.net/baidu_26137595/article/details/124021788)

### Code
第一部分：计算相关系数和P值（注意填补缺失值）


```python
from scipy.stats import pearsonr,spearmanr,kendalltau
# 存储未通过检测的属性对及其相关系数
non_significant_pairs = []

for i in range(len(continuous_cols_selected)):
    for j in range(i+1,len(continuous_cols_selected)):
        variable1 = corr_exp_rh[continuous_cols_selected[i]]
        variable2 = corr_exp_rh[continuous_cols_selected[j]]
        
        p_value_warning = []
        
        print(f'{continuous_cols_selected[i]} and {continuous_cols_selected[j]}:')
        # 计算Pearson相关系数及其P-value
        pearson_corr, peason_p_value = pearsonr(variable1,variable2)
        p_value_warning.append(peason_p_value)
        print(f'Pearson correlation :{pearson_corr},p-value:{peason_p_value}')
        
        # 计算Spearman相关系数及其P-value
        spearman_corr, spearman_p_value = spearmanr(variable1,variable2)
        p_value_warning.append(spearman_p_value)
        print(f'Spearman correlation :{spearman_corr},p-value:{spearman_p_value}')
        
        # 计算Kendall相关系数及其P-value
        kendall_corr, kendall_p_value = kendalltau(variable1,variable2)
        p_value_warning.append(kendall_p_value)
        print(f'Kendall correlation between :{kendall_corr},p-value:{kendall_p_value}')
        
        beyond_threshold = any(p > 0.05 for p in p_value_warning)
        if beyond_threshold:
            non_significant_pairs.append(
                (continuous_cols_selected[i], continuous_cols_selected[j], pearson_corr, spearman_corr, kendall_corr)
            )
# 输出未通过检测的属性对及其相关系数
print("-------------------------未通过p-value检测的属性对及其相关系数:-----------------------------------")
for pair in non_significant_pairs:
    attr1, attr2, pearson_corr, spearman_corr, kendall_corr = pair
    print(f"{attr1} and {attr2}: Pearson={pearson_corr}, Spearman={spearman_corr}, Kendall={kendall_corr}")
```


第二部分：输出关系矩阵

```python
# 生成一个空矩阵
correlation_matrix_pearson = np.zeros((len(continuous_cols_selected),len(continuous_cols_selected)))
correlation_matrix_spearman = np.zeros((len(continuous_cols_selected),len(continuous_cols_selected)))
correlation_matrix_kendall = np.zeros((len(continuous_cols_selected),len(continuous_cols_selected)))

for i in range(len(continuous_cols_selected)):
    for j in range(i,len(continuous_cols_selected)):
        variable1 = corr_exp_rh[continuous_cols_selected[i]]
        variable2 = corr_exp_rh[continuous_cols_selected[j]]
        
        # 计算Pearson相关系数
        pearson_corr, peason_p_value = pearsonr(variable1,variable2)
        correlation_matrix_pearson[i][j] = pearson_corr
        #correlation_matrix_pearson[j][i] = pearson_corr
        
        
        # 计算Spearman相关系数
        spearman_corr, spearman_p_value = spearmanr(variable1,variable2)
        correlation_matrix_spearman[i][j] = spearman_corr

        
        # 计算Kendall相关系数及其P-value
        kendall_corr, kendall_p_value = kendalltau(variable1,variable2)
        correlation_matrix_kendall[i][j] = kendall_corr

pearson = pd.DataFrame(correlation_matrix_pearson,columns=continuous_cols_selected)
pearson.to_excel('correlation_matrix_pearson.xlsx',index=False)

spearman = pd.DataFrame(correlation_matrix_spearman,columns=continuous_cols_selected)
spearman.to_excel('correlation_matrix_spearman.xlsx',index=False)

kendall = pd.DataFrame(correlation_matrix_kendall,columns=continuous_cols_selected)
kendall.to_excel('correlation_matrix_kendall.xlsx',index=False)
```


## 2 数值型（numerical）&类别型（categorical）之间的 相关系数

### <font color = red>由于通过了平均数编码，因此分析钢种编码和其他数值型变量的关系，直接使用三大相关系数的计算（缺乏依据。。？）</font>



1. **皮尔逊相关系数（Pearson Correlation Coefficient）：**
    - **适用范围：** 用于测量两个连续型变量之间的线性关系。
    - 用于衡量两个连续型变量之间的线性关系；但是对于非线性关系&异常值敏感
    - 对于类别型变量，可以考虑将其转换为虚拟变量（独热编码）并计算它们之间的相关性。

2. **斯皮尔曼相关系数（Spearman Rank Correlation Coefficient）：**
    - **适用范围：** 用于测量两个变量之间的单调关系，不要求变量是连续的does not require variables to be continuous.
    - 用于测量两个变量之间的单调关系，不要求变量是连续的。
    - 对于类别型变量，可以使用它来考察它们之间的关系
    - **Advantages:** Robust to outliers, suitable for non-linear relationships.对数据分布没有强制要求
    - **Disadvantages:** Computationally slower compared to Pearson.

3. **点二列相关系数（Point-Biserial Correlation Coefficient）：**
    - **Applicability:** Suitable  `only` for the relationship between **a binary variable and a continuous variable**.
    - 适用于一个二元变量和一个连续变量之间的关系。

4. **Cramér's V：**
    - **Applicability:** Used for relationships between two categorical variables, a variant of the chi-square test适用于两个分类变量之间的关系，是卡方检验的一种.
    - **Disadvantages:** May be unstable for `small sample sizes`.

5. **ANOVA（方差分析）：**
    - **Applicability:** Suitable for the relationship between one categorical variable and one continuous variable.
    - 适用于一个类别型变量和一个连续型变量之间的关系，特别是当类别型变量有多个水平（多分类）时。
    - **Advantages:** 可以同时考虑多分类变量？Can consider multiple category levels simultaneously.
    - **Disadvantages:** 对于高度偏斜的数据不适用May be unstable for highly skewed data，且对异常值敏感

6. **Kruskal-Wallis检验**：**
	ANOVA对正态分布的假设较为敏感，如果数据严重偏斜或不符合正态分布，可能会影响结果的可靠性。
	- Kruskal-Wallis检验对数据分布要求较少，是一种非参数方法，对偏斜的数据和异常值也相对稳健。

```python
import scipy.stats as stats

# 假设你的数据框为df，其中包含了类别型变量（category_column）和平均数编码后的数值型变量（numeric_column）
category_column = 'your_category_column'
numeric_column = 'your_numeric_column'

# 使用Kruskal-Wallis检验
statistic, p_value = stats.kruskal(*[group[1][numeric_column] for group in df.groupby(category_column)])
print(f"Kruskal-Wallis Statistic: {statistic}")
print(f"P-value: {p_value}")

# 判断显著性
alpha = 0.05
if p_value < alpha:
    print("差异显著，可以拒绝原假设")
else:
    print("差异不显著，不能拒绝原假设")

```

7. **互信息（Mutual Information）：**
    - **Applicability:** Used to measure non-linear relationships between two variables, applicable to both categorical-categorical and categorical-numeric scenarios.
    - 用于测量两个变量之间的非线性关系，既可以用于类别型变量之间，也可以用于类别型和数值型变量之间。
    - **Advantages:** Captures non-linear relationships.
    - **Disadvantages:** Computationally slow for large datasets.对于大数据集可能性能表现较差

```python
from sklearn.feature_selection import mutual_info_regression

# 计算互信息
mi = mutual_info_regression(df[[category_column]], df[numeric_column])

print(f"Mutual Information between {category_column} and {numeric_column}: {mi}")

```

#### 可视化手段：箱线图
```python
import seaborn as sns
import matplotlib.pyplot as plt

# 箱线图
# 类别型
categorical_cols_selected = ['首件标识', '炉座号', '是否浇余','班次_bof', '班别_bof', '作业人员_bof', 
                    'LF号','班次_lf', '班别_lf', '作业人员_lf', 
                    #'RH机号', 'RH坑号', '目标钢种描述_rh', '班次', 
                    '班别', '作业人员', '连铸机号', 'RH真空处理', '是否低磷钢', '是否低碳钢', '是否低硫钢',
                     '是否低磷低碳低硫钢', '班次_cc', '班别_cc', '作业人员_cc','LF处理', '是否缺少精炼处理'
                   #,'steel_code', 'target_steel_code_rh'
                    #, '计划工艺路径'
                   ]
steel_col = ['steel_code', 'target_steel_code_rh']

# 创建箱线图
fig, axes = plt.subplots(nrows=len(categorical_cols_selected), ncols=len(steel_col), figsize=(15, 75))

for i, cat_col in enumerate(categorical_cols_selected):
    for j, steel_value in enumerate(steel_col):
        sns.boxplot(x=cat_col, y=steel_value, data=tmp, ax=axes[i, j])
        axes[i, j].set_title(f'{cat_col} vs {steel_value}')

plt.tight_layout()
plt.show()

# 直方图
sns.histplot(x=numeric_column, hue=category_column, data=df, kde=True)
plt.show()

```



## 3 类别型（categorical）之间的 相关系数

### （1） **卡方检验（Chi-Square Test）:**

- 用于检验两个分类变量之间是否存在关联。它适用于两个分类变量，检验它们的分布是否独立。
- 卡方检验对数据的分布并没有过多的要求，但是需要确保样本足够大，以满足检验的统计学要求
- **缺点：** 对样本大小敏感，当样本较小时可能导致不稳定的结果。受限于只能用于两个分类变量的关联性检验。

```python
from scipy.stats import chi2_contingency

# 示例数据
observed_data = pd.crosstab(df['Category1'], df['Category2'])

# 进行卡方检验
chi2, p, _, _ = chi2_contingency(observed_data)
print(f"Chi-Square Statistic: {chi2}")
print(f"P-value: {p}")

```

### （2）  **Cramér's V 统计量:**

- 适用于**卡方检验后发现存在关联的情况**，用于衡量两个分类变量之间的关联强度。
- 对数据分布并没有太多的要求，但样本大小应足够大
- **优点：** 提供了关联性的强度度量，可以用于两个分类变量的关联性检验。
- **缺点：** 仍然对样本大小敏感。对于较大的表格，即使两个变量之间的关联很小，也可能产生显著的结果——对于大样本量可能会导致即使关联很小也显得显著。（因为在大样本中，统计检验可能更容易检测到任何大小的关联，即使这种关联在实际中可能并不重要）

具体而言，Cramér's V 的计算中包括了卡方检验的结果，而卡方检验对于大样本量可能会导致拒绝原假设（即两个变量独立）的概率增加。因此，对于大样本，即使关联很小，也可能得到显著的 Cramér's V。

在实际应用中，对于大样本，可能更关注关联的强度而不仅仅是统计显著性。因此，需要谨慎解释 Cramér's V 的结果。
```python
import numpy as np

def cramers_v(confusion_matrix):
    chi2 = chi2_contingency(confusion_matrix)[0]
    n = confusion_matrix.sum()
    phi2 = chi2 / n
    r, k = confusion_matrix.shape
    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))
    rcorr = r - ((r-1)**2)/(n-1)
    kcorr = k - ((k-1)**2)/(n-1)
    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))

# 示例数据
observed_data = pd.crosstab(df['Category1'], df['Category2'])

# 计算 Cramér's V
cramers_v_value = cramers_v(observed_data.values)
print(f"Cramér's V: {cramers_v_value}")

```

### 3. **熵相关性（Entropy-Based Measures）:**

- 使用熵相关性来衡量两个分类变量之间的关联。常见的熵相关性指标包括互信息（Mutual Information）和规范化互信息（Normalized Mutual Information）。
- 互信息和规范化互信息，它们对数据分布没有特定的要求，但由于计算涉及到概率分布，需要确保样本足够大
- **优点：** 不仅仅限于两个变量，可以适用于多个分类变量的关联性检验。提供了丰富的信息度量。
- **缺点：** **对于不平衡数据集，可能会受到较为严重的影响**。对于较大的数据集，计算可能较为耗时。

```python
from sklearn.metrics import mutual_info_score, normalized_mutual_info_score

# 示例数据
mi = mutual_info_score(df['Category1'], df['Category2'])
nmi = normalized_mutual_info_score(df['Category1'], df['Category2'])

print(f"Mutual Information: {mi}")
print(f"Normalized Mutual Information: {nmi}")


```


#### <font color = red>但问题在于，我的类别变量就是大规模+不平衡；这也就意味着，无论是卡方还是熵相关方法，得到的效果应该都会受限；不过因为这些分类变量之间的关系，似乎也没有那么重要。因为现在只是在进行相关性分析的阶段，后续还会通过特征工程等训练过程降维，所以其实这个步骤不做应该也没多大影响?</font>
*后续如果还有问题，再看看有无解决方案？


1. **Chi-Squared Test**:
    
    - The **chi-squared statistic** measures the association between two categorical variables.
    - It assesses whether the observed frequency distribution differs significantly from the expected distribution (assuming independence).
    - Calculate the chi-squared value for each pair of categorical features.
    - High chi-squared values indicate strong association.
2. **Cramér’s V**:
    
    - Cramér’s V is a measure of association for nominal (categorical) variables.
    - It is based on the chi-squared statistic and accounts for the number of categories in each variable.
    - Higher Cramér’s V values indicate stronger association.
3. **Contingency Tables and Heatmaps**:
    
    - Create a **contingency table** (cross-tabulation) for pairs of categorical features.
    - Visualize the table using a **heatmap** to highlight associations.
    - Darker cells represent stronger associations.
4. **Correspondence Analysis (CA)**:
    
    - CA is a dimensionality reduction technique for categorical data.
    - It helps visualize relationships between categorical variables.
    - CA plots variables and categories in a low-dimensional space, emphasizing associations.
5. **Pairwise Association Measures**:
    
    - Explore other pairwise association measures such as **point-biserial correlation**, **phi coefficient**, or **odds ratio**.
    - These measures provide insights into the strength and direction of association.
6. **Domain Knowledge and Context**:
    
    - Consider the context of your problem and domain-specific knowledge.
    - Some associations may make sense intuitively even without statistical tests.

Remember that correlation doesn’t imply causation, and further exploration may be necessary