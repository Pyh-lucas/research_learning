#å½’ä¸€åŒ–

ä¸­å¿ƒåŒ– Zero-centeredï¼šè®©æ‰€æœ‰è®°å½•å‡å»ä¸€ä¸ªå›ºå®šå€¼ï¼Œè®©æ•°æ®å¹³ç§»åˆ°æŸä¸€ä¸ªä½ç½®

ç¼©æ”¾å¤„ç†Scaleï¼šé€šè¿‡é™¤ä»¥ä¸€ä¸ªå›ºå®šå€¼ï¼Œå°†æ•°æ®å›ºå®šåœ¨æŸä¸ªèŒƒå›´ä¸­ï¼Œå–å¯¹æ•°ä¹Ÿç®—æ˜¯ä¸€ç§ç¼©æ”¾

[sklearn.preprocessing.normalize â€” scikit-learn 1.3.2 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html)

1. **What is Normalizationï¼ˆMax-Min Scalingï¼‰ç‰¹æŒ‡æœ€å¤§æœ€å°å€¼å½’ä¸€åŒ–?**
	    æŒ‰ç…§æœ€å°å€¼ä¸­å¿ƒåŒ–ä¹‹åï¼Œå†æŒ‰æå·®ç¼©æ”¾ï¼Œå°†æ•°æ®æ”¶æ•›åˆ°0-1ä¹‹é—´ï¼Œå½’ä¸€åŒ–åæ•°æ®æœä»æ­£æ€åˆ†å¸ƒ
    - **Normalization** involves **scaling** the data to a common range. The goal is to transform the data so that it falls within a specific interval (often between 0 and 1 or -1 and 1).
    - Machine learning algorithms tend to perform better when features are on a smaller scale. Normalization helps achieve this by making the data more suitable for training.
2.  **æŒ‰ç…§å‡å€¼å’Œæ ‡å‡†å·®è¿›è¡Œç¼©æ”¾ï¼šStandnrdization /Z-Score normalizationï¼Œæ•°æ®æ ‡å‡†åŒ–ï¼Œä½¿ä¹‹æˆä¸º0å‡å€¼1æ–¹å·®çš„æ ‡å‡†æ­£æ€åˆ†å¸ƒ**


ä¸€èˆ¬æ¥è¯´ï¼Œå¤§å¤šæ•°æœºå™¨å­¦ä¹ ç®—æ³•ä¸­ä¼šé€‰æ‹©StandardScalerè¿›è¡Œç‰¹å¾ç¼©æ”¾ï¼Œå› ä¸ºMinMaxScalerå¯¹å¼‚å¸¸å€¼æ•æ„Ÿã€‚å°¤å…¶PCAï¼Œèšç±»ï¼ŒLogisticå›å½’ã€æ”¯æŒå‘é‡æœºã€NNä¸­ï¼ŒStandardScalerå¾€å¾€æ˜¯æœ€å¥½çš„

MinMaxScaleråœ¨ä¸æ¶‰åŠè·ç¦»åº¦é‡ã€æ¢¯åº¦ã€åæ–¹å·®è®¡ç®—ï¼Œä»¥åŠæ•°æ®éœ€è¦è¢«å‹ç¼©åˆ°ç‰¹å®šåŒºé—´æ—¶åº”ç”¨å¹¿æ³›ã€‚
ä¸€èˆ¬æ¥è¯´ï¼Œå…ˆè¯•è¯•çœ‹æ ‡å‡†åŒ–ï¼Œæ•ˆæœä¸å¥½å†å°è¯•å½’ä¸€åŒ–ã€‚

sklearnä¸­è¿˜åŒ…å«å…¶ä»–ç¼©æ”¾å¤„ç†ï¼š
å¸Œæœ›å‹ç¼©æ•°æ®ï¼Œä½†ä¸å½±å“æ•°æ®ç¨€ç–æ€§ï¼ˆä¸å½±å“çŸ©é˜µä¸­å–å€¼ä¸º0çš„ä¸ªæ•°æ—¶ï¼‰ï¼Œä½¿ç”¨MaxAbsScalerï¼›
åœ¨å¼‚å¸¸å€¼å¤šï¼Œå™ªå£°éå¸¸å¤§æ—¶ï¼Œå¯èƒ½ä¼šé€‰ç”¨åˆ†ä½æ•°æ¥æ— é‡çº²åŒ–ï¼šRobustScaler




**Data preprocessing** is a crucial step in preparing raw data for analysis, especially when working with machine learning or data mining algorithms. Letâ€™s focus on **normalization**, which is one of the essential techniques in data preprocessing.

2. **Methods for Normalization:**
    
    - **Min-Max Normalization (Scaling):** Scales the data to a specified range (e.g., [0, 1]).
    - **Z-Score Normalization (Standardization):** Transforms the data to have a mean of 0 and a standard deviation of 1.
    - **Decimal Scaling:** Shifts the decimal point of the data values.
    - **L2 Normalization (Euclidean Norm):** Scales vectors individually to have a length of one.
3. **Using scikit-learn for Normalization:**
    
    - The `scikit-learn` library provides the `preprocessing.normalize()` function.
    - It scales vectors individually to a unit norm (default is L2 norm).
    - Example using a one-dimensional NumPy array:
        
        ```python
        import numpy as np
        from sklearn import preprocessing
        
        x_array = np.array([2, 3, 5, 6, 7, 4, 8, 7, 6])
        normalized_arr = preprocessing.normalize([x_array])
        print(normalized_arr)
        ```
        
        Output:
        
        ```
        [[0.11785113 0.1767767 0.29462783 0.35355339 0.41247896 0.23570226
          0.47140452 0.41247896 0.35355339]]
        ```
        
        The values are now in the range [0, 1], and their sum of squares is approximately 1.
4. **Normalizing Columns from a DataFrame:**
    
    - In a pandas DataFrame, you can normalize columns (features) using the same `preprocessing.normalize()` function.
    - Example using the California Housing dataset:
        
        ```python
        from sklearn import preprocessing
        import pandas as pd
        from sklearn.datasets import fetch_california_housing
        
        california_housing = fetch_california_housing(as_frame=True)
        scaler = preprocessing.MinMaxScaler(feature_range=(0, 2))
        d = scaler.fit_transform(california_housing.data)
        scaled_df = pd.DataFrame(d, columns=california_housing.data.columns)
        print(scaled_df)
        ```
        

Remember that the specific normalization method depends on your data and the problem youâ€™re solving. Choose the one that best suits your needs! ğŸ“ŠğŸ”



--------------------------------------------------
**Data preprocessing** is a crucial step in preparing raw data for analysis, especially when working with machine learning or data mining algorithms. Letâ€™s focus on **normalization**, which is one of the essential techniques in data preprocessing.

1. **What is Normalization?**
    
    - **Normalization** involves **scaling** the data to a common range. The goal is to transform the data so that it falls within a specific interval (often between 0 and 1 or -1 and 1).
    - Machine learning algorithms tend to perform better when features are on a smaller scale. Normalization helps achieve this by making the data more suitable for training.
2. **Methods for Normalization:**
    
    - **Min-Max Normalization (Scaling):** Scales the data to a specified range (e.g., [0, 1]).
    - **Z-Score Normalization (Standardization):** Transforms the data to have a mean of 0 and a standard deviation of 1.
    - **Decimal Scaling:** Shifts the decimal point of the data values.
    - **L2 Normalization (Euclidean Norm):** Scales vectors individually to have a length of one.
3. **Using scikit-learn for Normalization:**
    
    - The `scikit-learn` library provides the `preprocessing.normalize()` function.
    - It scales vectors individually to a unit norm (default is L2 norm).
    - Example using a one-dimensional NumPy array:
        
        ```python
        import numpy as np
        from sklearn import preprocessing
        
        x_array = np.array([2, 3, 5, 6, 7, 4, 8, 7, 6])
        normalized_arr = preprocessing.normalize([x_array])
        print(normalized_arr)
        ```
        
        Output:
        
        ```
        [[0.11785113 0.1767767 0.29462783 0.35355339 0.41247896 0.23570226
          0.47140452 0.41247896 0.35355339]]
        ```
        
        The values are now in the range [0, 1], and their sum of squares is approximately 1.
4. **Normalizing Columns from a DataFrame:**
    
    - In a pandas DataFrame, you can normalize columns (features) using the same `preprocessing.normalize()` function.
    - Example using the California Housing dataset:
        
        ```python
        from sklearn import preprocessing
        import pandas as pd
        from sklearn.datasets import fetch_california_housing
        
        california_housing = fetch_california_housing(as_frame=True)
        scaler = preprocessing.MinMaxScaler(feature_range=(0, 2))
        d = scaler.fit_transform(california_housing.data)
        scaled_df = pd.DataFrame(d, columns=california_housing.data.columns)
        print(scaled_df)
        ```
        

Remember that the specific normalization method depends on your data and the problem youâ€™re solving. Choose the one that best suits your needs! ğŸ“ŠğŸ”